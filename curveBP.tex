\documentclass[12pt]{article}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amssymb,amsmath,amsthm}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage[nameinlink,capitalize]{cleveref}
\usepackage{cleveref}
\usepackage[margin=1in]{geometry}
\usepackage{lineno}\renewcommand\thelinenumber{\color{gray}\arabic{linenumber}}
\usepackage{pdflscape}
\usepackage{xspace}
\usepackage{array}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\newcommand{\comment}{\showcomment}
\newcommand{\showcomment}[3]{\textcolor{#1}{\textbf{[#2: }\textsl{#3}\textbf{]}}}
\newcommand{\nocomment}[3]{}
\newcommand{\pkg}[1]{\textsf{#1}}  %{\texttt{#1}}

\newcommand{\ali}[1]{\comment{magenta}{Ali}{#1}}
\newcommand{\bmb}[1]{\comment{red}{BMB}{#1}}
\newcommand{\todo}[1]{\comment{red}{TODO}{#1}}

\theoremstyle{definition} % amsthm only
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
 
\bibliographystyle{apalike}

\title{Centrality: A Curve-Based Statistical Discription of an Ensemble}
\author{Ali Gharouni, Ben Bolker}
\begin{document}
\maketitle
\linenumbers

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Abstract}
This is a commentary work motivated by \cite{juul2021fixed}'s work in which a few useful ideas of the concept of the central set out of an ensemble of epidemic curves were presented. In the present work we provide alternative, and more principled, curved-based statistics approaches to approximate the most central set which represents the central 50\% of the ensemble. In particular, we use three functional ranking methods; (1) the sampling-based, fast and robust functional boxplot, 
(2) pairwise distances (eg, $\ell_2$ norm) between the curves and quantiles of centrality, and (3) a multivariate generalization of ranking the curves by using Mahalanobis distance among features of interest. We apply our methods on \cite{juul2021fixed}'s dataset and compare our results with theirs.      

\section{Introduction}

\cite{juul2021fixed} pointed out some shortcomings of standard pointwise-quantile (fixed-time) approaches to confidence intervals for curves, in the context of ensembles of epidemic curves generated by stochastic models. In particular, they showed that fixed-time approaches can fail to capture the uncertainty in key features of an epidemic such as the timing and magnitude of epidemic peaks.  As an alternative to fixed-time approaches, the authors illustrated methods to compute the \emph{central set} of an ensemble of curves, a high-dimensional analogue of interquartile range or confidence interval. There is a large body of literature on this topic under the rubrics of \emph{functional depth} and \emph{functional boxplots} for high dimensional data \citep{fraiman2001trimmed, lopez2007depth, lopez2009concept, sun2011functional,sun2012exact}. While \cite{juul2021fixed} do cite this literature \citep{sun2011functional}, exploring this literature led us to several useful practical and theoretical points that could be useful for researchers interested in implementing these approaches in their own work.

%% However, the reason/potential advantage of aparting from the standard functional boxplot framework is unclear \ali{to be toned down a bit?!}.  

%% presented the following useful curve-based alternative methods to the fixed-time statistics of epidemic curve ensembles; (i) all-or-nothing ranking method (presented in their Fig.2b,c), (ii) weighted ranking (presented in their Fig.2d) and (iii) according to some feature of interest, e.g. the projected peak value (presented in their Fig.2e). Note that (i) and (ii) are sampling-based approaches and (iii) is a featur-based ranking approach. They cautioned that standard pointwise (fixed-time) averages may not be appropriate to summerize ensembles of epidemic curves. Particularly, they discussed that miscapturing key features of an epidemic such as the peak numbers of infections, the time of the peak, etc. may result in obscuring the forcast process. While Juul et al.'s implimented their methodology in sampling-based functional ranking and establishing the most ``central set'' of an ensemble, there is a deep existing literature in functional depth, functional boxplot, and centrality metrics for high dimension data \citep{fraiman2001trimmed, lopez2007depth, lopez2009concept, sun2011functional,sun2012exact}. It appears that \cite{juul2021fixed} were aware of the functional boxplot concept, since they cited the work by \cite{sun2011functional}. However, the reason/potential advantage of aparting from the standard functional boxplot framework is unclear \ali{to be toned down a bit?!}.  


%The idea of the functional boxplot goes back farther to the notion of depth. It was first introduced for multivariate data in an attempt to generalize the ideas of order statistics, ranks and medians into higher dimensions (see for e.g., \cite{mahalanobis1936generalized,tukey1975mathematics}). The notion of depth was extended for functional data by \citep{lopez2009concept}. They introduced the concept of band depth (BD) for ranking a sample of functional data from the center outward. This ordering enables us to define the functional quantiles, centrality or outlyingness of an observation. Further, the classical boxplot for univariate data was extended to the functional boxplots and adjusted functional boxplots as a visualization tool \citep{sun2011functional,sun2012adjusted}.

\newcommand{\ncurve}{\ensuremath{N_{\textrm{curves}}}\xspace}
\newcommand{\nsample}{\ensuremath{N_{\textrm{samples}}}\xspace}

\cite{juul2021fixed}'s primary approach to determine the centrality (and hence whether it should be included in a central set of curves for display) was to measure the fraction of times that a given curve is completely included within the envelope of a set of $\ncurve=50$ other randomly sampled curves from the ensembles; they chose $\nsample=100$ sets of such samples to compute the fraction. \cite{juul2021fixed} provide open-source Python code that implements this method, as well as some of the weighted variants they discuss. For the simple (unweighted) case, however, there are already mature open source implementations available in R \citep{fda_pkg,roahd}, Matlab (\url{https://www.psych.mcgill.ca/misc/fda/downloads/FDAfuns/}), and Python \citep{seabold2010statsmodels}). In general these packages use the same functional band depth measure as \cite{juul2021fixed}, but generally using $\ncurve=2$, which is robust and allows the use of a computationally efficient algorithm for large data sets \citep{sun2012exact}.

\bmb{what else do \cite{sun2012exact} say about tradeoffs (other than computational) for using larger values of \ncurve \ldots ? Any clues as to why Juul et al might have chosen their values?}

%We note that \cite{juul2021fixed}'s sampling-based approach is a special case of functional depth in which the robustness and optimized computational cost of the functional band depth is known \citep{sun2012exact}. The computational cost is determined by the sample size of the ensemble $n$ and the number of curves $j$ defining a band/envelope ($2\leq j \leq J$). \cite{sun2012exact} discussed the robustness and sensibility of small values of $J$, and in particular $J=2$ is suggested for large datasets. 
%It is notable that \cite{juul2021fixed}'s sampling-based approach is a special case of functional depth, where $n=500$ and $J=50$ (in their paper: $N_{\rm{curves}}=50$) and random samples were uniformly drawn $N_{\rm{samples}}=100$ times. Likewise the functional depth method, the centrality scores of all curves in the ensemble were updated based on whether the entire curve is contained in the sample-specific envelope. The most central curves are the ones with their scores above the 50\% percentile of scores. Here, we use the functional boxplot on \cite{juul2021fixed}'s dataset, thus ${500}\choose{2}$ samples determine the centrality scores.


Specifically, we used the function fda() in R \citep{R} package \pkg{roahd} \citep{roahd}, with the choice of modified band depth (MBD) to break ties which is based on the fast algorithm proposed by \cite{sun2012exact}. 

We also use pairwise distances between the curves and quantiles of centrality as an alternative method to a sampling-based functional boxplot. In particular, we compute all pairwise distances -- here we used $\ell_2$ norm which gives the area between the two curves -- between the curves, determine the median-like distance of a curve to all others as the minimum of sum of distances, estimate the distribution of distances. The curve-based descriptive statistics is as follows;
(1) ranking the curves from more central, i.e., closer to the distribution median (or mean) to less central, and (2) plot the envelope containing the most central curves, i.e. the pointwise min/max curves of a subset of curves with the lowest sum (or sum of squares) of distances to the other curves. Note that the distribution median and mean are highly correlated and in this context median makes the most sense because \ali{...?}. Also, the most central set depends on the choice of the functional norm and further research is needed for clarification. We caution that functional norms that gives a distance of exactly zero on a slightly time-shifted step function (e.g., Fr√©chet distance and dynamic time-warping \ali{refs?}) seems inappropriate.

\cite{juul2021fixed} also provided an example of functional ranking according to a some feature of interest, maximum values of newly hospitalized cases in a single day (Fig.~2e). The multivariate generalization of this approach can be implemented by using an appropriate metric among features. In particular, we considered the set of all vectors, in which a curve-specific vector contains features of interest. We used the Mahalanobis distance \citep{mahalanobis1936generalized} to rank these feature vectors. 
The envelope of the most central curves includes the curves with the rank within the 50\% quantile. The Mahalanobis distance provides a measure of similarity between multivariate data and uses covariance information between features to weight the contributions to the distance. The Euclidean distance, on the other hand, in essence gives excess weight to variables (features) that are highly correlated and gives additional weight to variables that have similar information. The Mahalanobis distance gives less weight to those variables that have high variance and to those variables that have high correlation, so that other feature variables with lower correlations can contribute to the distance. One potential problem with Mahalanobis distances: if (for example) the probe distribution is strongly bimodal, then scaling factors/correlations derived from the overall data set may not be appropriate for scaling the components of distance between two trajectories whose features
put them in the same mode/component of the distribution.  The epidemic features of interest that we considered here include the peak value of newly infections, time of the peak, final size of the epidemic, epidemic duration and the initial growth rate of the infection. Note that the choice of the epidemic features depends on the objectives of the study (see for e.g., \cite{probert2016decision}).

\section{Results}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{scripts/cent_plot.pdf}
\caption{Comparison of alternative methods of functional boxplots.}\label{p.a}
\end{figure}


\bibliography{./AliMac}
\end{document}
